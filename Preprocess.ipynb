{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "from imutils import contours\n",
    "import imutils\n",
    "from skimage import measure\n",
    "import cv2\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "IMAGE_REGEX = re.compile(\".*?\\.(png|jpe?g)$\", flags = re.IGNORECASE)\n",
    "TOP_LEVEL = os.path.expanduser(\"~/Desktop/jmk/ArthroplastyID/HIPS/\")\n",
    "_IMAGE_EXTENSION = 'png'\n",
    "\n",
    "def _show(image):\n",
    "    plt.figure()\n",
    "    imshow(np.asarray(image))\n",
    "    return\n",
    "\n",
    "def _convert_rgba_rgb(image):\n",
    "    image.load()\n",
    "    background = Image.new(\"RGB\", image.size, (255, 255, 255))\n",
    "    background.paste(image, mask=image.split()[3]) # 3 is the alpha channel\n",
    "    return background\n",
    "\n",
    "def _load(path):\n",
    "    r = Image.open(path)\n",
    "    return r\n",
    "\n",
    "def _crop(image, coords):\n",
    "    return image.crop(coords)\n",
    "\n",
    "def _smart_crop_coordinates(image, x_lim=300, y_lim = 300):\n",
    "    sc = smartcrop.SmartCrop(rule_of_thirds = False,\n",
    "                            skin_weight = 0,\n",
    "                            saturation_weight = 1)\n",
    "    result = sc.crop(image, x_lim, y_lim)\n",
    "    left = result['top_crop']['x']\n",
    "    top = result['top_crop']['y']\n",
    "    right = left + result['top_crop']['width']\n",
    "    bottom = top + result['top_crop']['height']\n",
    "    return (left, top, right, bottom)\n",
    "\n",
    "def auto_crop_main(image, _SIZE_THRESHOLD = 300, debug = False):\n",
    "    # if both coord > 300 -> image detection at 300x300\n",
    "    # if largest coord > 300 but smallest coord < 300 -> object detection at 300x300\n",
    "    # if max (coords) > 300, pad small coord with black to make a square\n",
    "    # if both coord < 300 -> box to 300\n",
    "    # All, then downsize to 200x200\n",
    "    if(isinstance(image, str)):\n",
    "        image = _load(image_path)\n",
    "        image = _convert_rgba_rgb(image)\n",
    "    width,height = image.size\n",
    "    if debug:\n",
    "        print (\"{}: {}x{}\".format(os.path.basename(image_path),height,width))\n",
    "    if max(height, width) > _SIZE_THRESHOLD:\n",
    "        coords = _smart_crop_coordinates(image, x_lim = _SIZE_THRESHOLD, y_lim = _SIZE_THRESHOLD)\n",
    "        left, top, right, bottom = coords\n",
    "        new_height = bottom - top\n",
    "        new_width = right - left\n",
    "        if debug:\n",
    "            print('Height: ({} -> {}); Width: ({} -> {})'.format(height, new_height, width, new_width))\n",
    "            print(coords)\n",
    "        y_pad = _SIZE_THRESHOLD - new_height\n",
    "        x_pad = _SIZE_THRESHOLD - new_width\n",
    "        #prioritize symmetric x padding\n",
    "        #stretch image if goes over\n",
    "        new_left = left - x_pad/2\n",
    "        new_left = 0 if new_left < 0 else new_left\n",
    "        new_right = new_left + _SIZE_THRESHOLD\n",
    "        new_right = right if new_right < width else width\n",
    "        # prioritize bottom y padding\n",
    "        new_bottom = bottom + y_pad\n",
    "        if new_bottom > height:\n",
    "            new_bottom = height \n",
    "            # if not all padding used, remove from new_top\n",
    "            new_top = top - (_SIZE_THRESHOLD - new_bottom)\n",
    "            new_top = new_top if new_top > 0 else 0\n",
    "        else:\n",
    "            new_top = top\n",
    "        left, top, right, bottom = (new_left, new_top, new_right,new_bottom)\n",
    "    else:\n",
    "        top = left = 0\n",
    "        bottom = height\n",
    "        right = width\n",
    "    return (left, top, right, bottom)\n",
    "\n",
    "def _resize(image, DIMENSION = 200):\n",
    "    if(isinstance(image, str)):\n",
    "        image = _load(image)\n",
    "    return image.resize((DIMENSION,DIMENSION),Image.LANCZOS)\n",
    "\n",
    "# Get the pixel from the given image\n",
    "def get_pixel(image, i, j):\n",
    "    # Inside image bounds?\n",
    "    width, height = image.size\n",
    "    if i > width or j > height:\n",
    "        return None\n",
    "\n",
    "    # Get Pixel\n",
    "    pixel = image.getpixel((i, j))\n",
    "    return pixel\n",
    "\n",
    "# Create a new image with the given size\n",
    "def create_image(i, j):\n",
    "    image = Image.new(\"RGB\", (i, j), \"white\")\n",
    "    return image\n",
    "\n",
    "# Create a Grayscale version of the image\n",
    "# Uses the ITU-R Recommendation BT.601-7 for converting \n",
    "def convert_grayscale(image):\n",
    "    # Get size\n",
    "    width, height = image.size\n",
    "\n",
    "    # Create new Image and a Pixel Map\n",
    "    new = create_image(width, height)\n",
    "    pixels = new.load()\n",
    "\n",
    "    # Transform to grayscale\n",
    "    for i in range(width):\n",
    "        for j in range(height):\n",
    "            # Get Pixel\n",
    "            pixel = get_pixel(image, i, j)\n",
    "            # Get R, G, B values (This are int from 0 to 255)\n",
    "            red =   pixel[0]\n",
    "            green = pixel[1]\n",
    "            blue =  pixel[2]\n",
    "\n",
    "            # Transform to grayscale\n",
    "            gray = (red * 0.299) + (green * 0.587) + (blue * 0.114)\n",
    "\n",
    "            # Set Pixel in new image\n",
    "            pixels[i, j] = (int(gray), int(gray), int(gray))\n",
    "\n",
    "    # Return new image\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get classess of all files in AP and Lateral Folders\n",
    "# regex: match any string that ends in .png, .jpeg, .jpg\n",
    "\n",
    "\n",
    "def image_search(files, regex):\n",
    "    ret = []\n",
    "    for f in files:\n",
    "        if regex.search(f):\n",
    "            ret.append(f)\n",
    "    return ret\n",
    "\n",
    "def parse_raw_class_names(files, view):\n",
    "    # returns dictionary:\n",
    "    # class : [DICT_1,, DICT_2, ..., DICT_k]\n",
    "    # where DICT = {PATH:path, BASE: os.path.basename, VIEW: AP | LATERAL}\n",
    "    class_regex = re.compile(\"(.*?)\\s*?(?:\\d|-)*\\s*?(?:\\(\\d\\)|\\d*|copy)+\\.(?:png|jpe?g)$\", flags = re.IGNORECASE)\n",
    "    d = {}\n",
    "    for f in files:\n",
    "        base = os.path.basename(f)\n",
    "        s = class_regex.search(base)\n",
    "        if s:\n",
    "            class_name = s.group(1).upper()\n",
    "            # the following makes this run much slower\n",
    "            class_name = re.sub('\\s+','+',class_name)\n",
    "            class_name = re.sub('-+','+',class_name)\n",
    "            if class_name not in d.keys():\n",
    "                d[class_name] = []\n",
    "            d[class_name].append({'PATH':f, 'BASE': base, 'VIEW': view})\n",
    "        else:\n",
    "            raise Exception(\"{} is not a valid image name\".format(f))\n",
    "    return d\n",
    "\n",
    "def get_filename_data(path):\n",
    "    # Expected format:\n",
    "    # '{CLASS}_{VIEW}_{INDEX}_{RESIZE}_{SET}_{AUGMENTID}.png'\n",
    "    base = os.path.basename(path)\n",
    "    _split = '.'.join(base.split('.')[:-1]).split('_')\n",
    "    _class = _split[0]\n",
    "    _view = _split[1]\n",
    "    _index = _split[2]\n",
    "    _resize = _split[3]\n",
    "    _set = _split[4]\n",
    "    _augment = _split[5]\n",
    "    return {\n",
    "        'CLASS':_class,\n",
    "        'VIEW':_view,\n",
    "        'INDEX':int(_index),\n",
    "        'RESIZE':int(_resize),\n",
    "        'SET':int(_set),\n",
    "        'AUGMENTID':_augment\n",
    "           }\n",
    "\n",
    "def make_filename(dictionary):\n",
    "    _rename_template = '{CLASS}_{VIEW}_{INDEX}_{RESIZE}_{SET}_{AUGMENTID}.{EXTENSION}'\n",
    "    _name = _rename_template.format(\n",
    "        CLASS = dictionary['CLASS'],\n",
    "        VIEW = dictionary['VIEW'],\n",
    "        INDEX = dictionary['INDEX'],\n",
    "        RESIZE = dictionary['RESIZE'],\n",
    "        SET = dictionary['SET'],\n",
    "        AUGMENTID = dictionary['AUGMENTID'],\n",
    "        EXTENSION = _IMAGE_EXTENSION\n",
    "        )\n",
    "    return _name\n",
    "\n",
    "def get_final_dict(AP, LATERAL, image_regex):\n",
    "    ap_files = image_search(glob.glob(AP + \"/*\"), image_regex)\n",
    "    lateral_files = image_search(glob.glob(LATERAL + \"/*\"), image_regex)\n",
    "\n",
    "    ap_dict = parse_raw_class_names(ap_files, \"AP\")\n",
    "    lateral_dict = parse_raw_class_names(lateral_files, \"LATERAL\")\n",
    "    \n",
    "    # merge dictionaries by class\n",
    "    final_dict = lateral_dict.copy()\n",
    "    for k in ap_dict.keys():\n",
    "        if k not in final_dict:\n",
    "            final_dict[k] = []\n",
    "        final_dict[k].extend(ap_dict[k])\n",
    "    return final_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# Separate images into directories by class\n",
    "# Move all images to the top level directory first for processing\n",
    "#####\n",
    "\n",
    "# convert path from TOP_LEVEL/VIEW to TOP_LEVEL/CLASS (class is key of dict)\n",
    "# resize 0 = not resized\n",
    "_RENAME_DEST = os.path.join(TOP_LEVEL, '1_RENAME')\n",
    "\n",
    "for key in final_dict.keys():\n",
    "    index = 1\n",
    "    for image in final_dict[key]:\n",
    "        path = image['PATH']\n",
    "        base = image['BASE']\n",
    "        view = image['VIEW']\n",
    "        # rename image to the following:\n",
    "        # CLASS_VIEW_INDEX_RESIZE\n",
    "        _class = key\n",
    "        _view = view\n",
    "        _index = index\n",
    "        index += 1\n",
    "        _resize = 0\n",
    "        _name = make_filename({\n",
    "            'CLASS': _class,\n",
    "            'VIEW': _view,\n",
    "            'INDEX': _index,\n",
    "            'RESIZE': _resize,\n",
    "            'SET': 0,\n",
    "            'AUGMENTID': 0}\n",
    "        )\n",
    "\n",
    "        src = path\n",
    "        dest = os.path.join(_RENAME_DEST,_name)\n",
    "        if not os.path.isdir(_RENAME_DEST):\n",
    "            os.mkdir(_RENAME_DEST)\n",
    "        shutil.copyfile(src, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# 2. Move files to new directory\n",
    "# New file structure:\n",
    "# TOP_LEVEL\n",
    "#     CLASS\n",
    "#          CLASS_VIEW_1_RESIZE...\n",
    "#          CLASS_VIEW_2_RESIZE...\n",
    "#####\n",
    "_SRC = os.path.join(TOP_LEVEL, '1_RENAME')\n",
    "_DEST = os.path.join(TOP_LEVEL, '2_ORGANIZED')\n",
    "# make dictionary of dictionaries for each class name\n",
    "classes = {}\n",
    "for file in image_search(glob.glob(os.path.join(_SRC,'*')), IMAGE_REGEX):\n",
    "    name = get_filename_data(file)\n",
    "    if name['CLASS'] not in classes:\n",
    "        classes[name['CLASS']] = []\n",
    "    classes[name['CLASS']].append(name)\n",
    "# for each class\n",
    "# make new folder within _DEST\n",
    "# make new file path\n",
    "# os.rename(src, dest)\n",
    "tocopy = []\n",
    "for _class in classes.keys():\n",
    "    _newdir = os.path.join(_DEST, _class)\n",
    "    if not os.path.isdir(_newdir):\n",
    "        os.mkdir(_newdir)\n",
    "    for item in classes[_class]:\n",
    "        _name = make_filename(item)\n",
    "        _oldfilename = os.path.join(_SRC, _name)\n",
    "        _newfilename = os.path.join(_newdir, _name)\n",
    "        #print(\"{} -> {}\".format(_oldfilename, _newfilename))\n",
    "        tocopy.append((_oldfilename, _newfilename))\n",
    "        \n",
    "for f in tqdm_notebook(tocopy):\n",
    "    shutil.copyfile(f[0],f[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new images from bryan to the repo\n",
    "# from BRYAN_ADDITIONS\n",
    "_src = os.path.expanduser(\"~/Desktop/jmk/ArthroplastyID/HIPS/BRYAN_ADDITIONS/Mixed 4.24.20\")\n",
    "_dest = os.path.expanduser(\"~/Desktop/jmk/ArthroplastyID/HIPS/2_ORGANIZED\")\n",
    "\n",
    "src_directories = [x[0] for x in os.walk(_src)]\n",
    "src_files = []\n",
    "for f in src_directories:\n",
    "        for x in glob.glob(f+'/*.png'):\n",
    "            src_files.append(x)\n",
    "            \n",
    "# make index directory\n",
    "index_d = {}\n",
    "for f in [x[0] for x in os.walk(_dest)][1:]:\n",
    "    c = f.split(os.sep)[-1]\n",
    "    index_d[c] = 0\n",
    "    for x in glob.glob(f+'/*.png'):\n",
    "        index_d[c] += 1\n",
    "            \n",
    "# rename and convert to grayscale\n",
    "for f in tqdm_notebook(src_files):\n",
    "    s = f.split(os.sep)\n",
    "    _class = s[-2]\n",
    "    if _class not in index_d.keys():\n",
    "        index_d[_class] = 0\n",
    "        os.mkdir(os.path.join(_dest, _class))\n",
    "    index_d[_class] += 1\n",
    "    _name = f[-1]\n",
    "    _newname = {'CLASS': _class,\n",
    "               'VIEW': 'AP' if re.search('(ap)', f, flags = re.IGNORECASE) else 'LATERAL',\n",
    "                'INDEX': index_d[_class],\n",
    "                'RESIZE': 0,\n",
    "                'SET':0,\n",
    "                'AUGMENTID':0\n",
    "               }\n",
    "    _newname = make_filename(_newname)\n",
    "    shutil.copyfile(f, os.path.join(_dest, _class, _newname))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# 2.5 - Make 2_ORGANIZED_AP, which just contains AP images from 2_ORGANIZED\n",
    "#####\n",
    "_SRC = os.path.join(TOP_LEVEL, '2_ORGANIZED')\n",
    "_DEST = os.path.join(TOP_LEVEL, '2_ORGANIZED_AP')\n",
    "dirs = [x[0] for x in os.walk(_SRC)][1:] # first is src, remove\n",
    "for d in dirs:\n",
    "    for image in image_search(glob.glob(os.path.join(d, '*')), IMAGE_REGEX):\n",
    "        _file = get_filename_data(image)\n",
    "        if _file['VIEW'] == 'AP':\n",
    "            _class = os.path.dirname(image).split(os.sep)[-1]\n",
    "            _newdir = os.path.join(_DEST, _class)\n",
    "            if not os.path.isdir(_newdir):\n",
    "                os.makedirs(_newdir)\n",
    "            shutil.copyfile(image, os.path.join(_newdir, os.path.basename(image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# 3. Make spreadsheet of images\n",
    "#####\n",
    "column_names = ['Implant', 'Num_AP', 'Num_LATERAL', 'Total', 'GT40']\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "_SRC = os.path.join(TOP_LEVEL, '2_ORGANIZED_AP')\n",
    "dirs = [x[0] for x in os.walk(_SRC)][1:] # first is src, remove\n",
    "for d in dirs:\n",
    "    num_ap = 0\n",
    "    num_lateral = 0\n",
    "    for image in image_search(glob.glob(os.path.join(d, '*')), IMAGE_REGEX):\n",
    "        _name = get_filename_data(image)\n",
    "        if _name['VIEW'] == 'LATERAL':\n",
    "            num_lateral += 1\n",
    "        else:\n",
    "            num_ap += 1\n",
    "        total = num_ap + num_lateral\n",
    "    toAdd = {'Implant' : os.path.basename(d).replace('+',' '),\n",
    "            'Num_AP' : num_ap,\n",
    "            'Num_LATERAL' : num_lateral,\n",
    "            'Total': total,\n",
    "            'GT40': total >= 40}\n",
    "    df = df.append(toAdd,ignore_index = True)\n",
    "df.to_csv('2_ORGANIZED_LIST.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# 4. Convert all images to grayscale and png\n",
    "#####\n",
    "\n",
    "_SRC = os.path.join(TOP_LEVEL, '3_GT20')\n",
    "_DEST = os.path.join(TOP_LEVEL, '4_GRAYSCALE')\n",
    "\n",
    "if not os.path.isdir(_DEST):\n",
    "    os.mkdir(_DEST)\n",
    "\n",
    "calls = []\n",
    "dirs = [x[0] for x in os.walk(_SRC)][1:]\n",
    "for d in dirs:\n",
    "    # 1 is directory\n",
    "    # 2 is directories (should be empty)\n",
    "    # 3 is filenames within #1\n",
    "    for image in image_search(glob.glob(os.path.join(d, '*')), IMAGE_REGEX):\n",
    "        _input = image\n",
    "        _class = os.path.dirname(image).split(os.sep)[-1]\n",
    "        _base = os.path.basename(image).split('.')[:-1]\n",
    "        _base = '.'.join(_base + [_IMAGE_EXTENSION]) # makes image png for saving\n",
    "        _output = os.path.join(_DEST, _class, _base)\n",
    "        calls.append((_input, _output))\n",
    "        \n",
    "        if not os.path.isdir(os.path.join(_DEST, _class)):\n",
    "            os.mkdir(os.path.join(_DEST, _class))\n",
    "        \n",
    "def wrapper(call):\n",
    "    image = _load(call[0])\n",
    "    gray = convert_grayscale(image)\n",
    "    gray.save(call[1])\n",
    "    return 1\n",
    "\n",
    "pool = Pool(processes=16)\n",
    "_sum = 0\n",
    "for _ in tqdm_notebook(pool.imap_unordered(wrapper, calls), total = len(calls)):\n",
    "    _sum += _\n",
    "print(\"Total images: {}\".format(str(_sum)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# There is no #5...\n",
    "# 6. After moving all included images to a separate directory, time to change the SET variable in the filenames\n",
    "# SET variable is 0 by default, definitions below\n",
    "# 0 - default, not set. Synonymous with NULL\n",
    "# 1 - training, needs to have augmentation done on this (next step)\n",
    "# 2 - validation, no augmentation needed\n",
    "# 3 - testing, no augmentation needed\n",
    "# NOTE: Im going to ignore imbalance for now, max imbalance is 10:1, which might be okay\n",
    "#####\n",
    "\n",
    "def split_train_val_test(list_of_images, train_frac = 0.8, val_frac = 0.1, random_state = 42):\n",
    "    assert (train_frac + val_frac) < 1.0\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    test_frac = 1 - (train_frac + val_frac)\n",
    "    train, rest = train_test_split(list_of_images, test_size = 1-train_frac, random_state = random_state)\n",
    "    test_from_rest_size = test_frac/(test_frac + val_frac)\n",
    "    val, test = train_test_split(rest, test_size = test_from_rest_size, random_state = random_state)\n",
    "    return train, val, test\n",
    "\n",
    "def copy_train_val_test(files, DESTINATION, IDENTIFIER):\n",
    "    for f in tqdm_notebook(files):\n",
    "        _n = get_filename_data(f)\n",
    "        # get second level directory (for the class name)\n",
    "        # normpath, sep on os.sep, get second to last\n",
    "        _class_dir = os.path.normpath(f).split(os.sep)[-2]\n",
    "        _n['SET'] = IDENTIFIER\n",
    "        _newname = make_filename(_n)\n",
    "        _newname = os.path.join(DESTINATION, _class_dir, _newname)\n",
    "        # make directory if not present\n",
    "        _newdir = os.path.dirname(_newname)\n",
    "        if not os.path.isdir(_newdir):\n",
    "            os.makedirs(_newdir)\n",
    "        shutil.copyfile(f, _newname)\n",
    "\n",
    "_SRC = os.path.join(TOP_LEVEL, '4_GRAYSCALE')\n",
    "_DEST = os.path.join(TOP_LEVEL, '5_EXPERIMENT_NAMES')\n",
    "dirs = [x[0] for x in os.walk(_SRC)][1:] # first is src, remove\n",
    "trains = []\n",
    "vals = []\n",
    "tests = []\n",
    "to_run = []\n",
    "for d in dirs:\n",
    "    if len(to_run) != 0 and sum(1 for x in to_run if d.endswith(x)) == 0:\n",
    "        continue\n",
    "    print('RUNNING ON: {}'.format(d))\n",
    "    files = [x for x in image_search(glob.glob(os.path.join(d,'*')), IMAGE_REGEX)]\n",
    "    train, val, test = split_train_val_test(files)\n",
    "    trains.extend(train)\n",
    "    vals.extend(val)\n",
    "    tests.extend(test)\n",
    "# change train filenames\n",
    "copy_train_val_test(trains, _DEST, 1)\n",
    "# change val filenames\n",
    "copy_train_val_test(vals, _DEST, 2)\n",
    "# change train filenames\n",
    "copy_train_val_test(tests, _DEST, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# 7. Test to make sure number of test, val, split images are as expected\n",
    "#####\n",
    "_out_string = 'DIRECTORY: {DIR}\\n\\tTRAIN: {train}\\n\\tVALIDATE: {val}\\n\\tTEST: {test}\\n\\tTOTAL: {total}'\n",
    "_SRC = os.path.join(TOP_LEVEL, '5_EXPERIMENT_NAMES')\n",
    "dirs = [x[0] for x in os.walk(_SRC)][1:] # first is src, remove\n",
    "for d in dirs:\n",
    "    files = [x for x in image_search(glob.glob(os.path.join(d,'*')), IMAGE_REGEX)]\n",
    "    num_train = num_val = num_test = 0\n",
    "    for f in files:\n",
    "        _n = get_filename_data(f)\n",
    "        if _n['SET'] == 1:\n",
    "            num_train += 1\n",
    "        if _n['SET'] == 2:\n",
    "            num_val += 1\n",
    "        if _n['SET'] == 3:\n",
    "            num_test += 1\n",
    "    print(_out_string.format(\n",
    "        DIR = os.path.basename(d),\n",
    "        train = num_train,\n",
    "        val = num_val,\n",
    "        test = num_test,\n",
    "        total = num_train + num_val + num_test\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# 8. Augment training images, copy all images to 6_EXPERIMENT_FINAL_ORIGINAL_SIZE\n",
    "#####\n",
    "_SRC = os.path.join(TOP_LEVEL, '5_EXPERIMENT_NAMES')\n",
    "_DEST = os.path.join(TOP_LEVEL, \"6_EXPERIMENT_FINAL_ORIGINAL_SIZE\")\n",
    "\n",
    "def make_augments(path, num):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        brightness_range=(0.5, 1.2),\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "    return_images = []\n",
    "    \n",
    "    # load image\n",
    "    img = _load(path)\n",
    "    img = img_to_array(img)\n",
    "    img = img.reshape((1,) + img.shape)\n",
    "    imgen = datagen.flow(img) # yields a generator object\n",
    "    \n",
    "    # make {num} random augmentations\n",
    "    for i in range(0,num):\n",
    "        nextimage = next(imgen)[0].astype(int)\n",
    "        aug_image = Image.fromarray(np.uint8(nextimage))\n",
    "        return_images.append(aug_image)\n",
    "    return return_images\n",
    "\n",
    "to_save = []\n",
    "dirs = [x[0] for x in os.walk(_SRC)][1:] # first is src, remove\n",
    "\n",
    "to_run = []\n",
    "for d in tqdm_notebook(dirs):\n",
    "    if d.startswith('.'):\n",
    "        continue\n",
    "    if len(to_run) != 0 and sum(1 for x in to_run if d.endswith(x)) == 0:\n",
    "        continue\n",
    "    print(\"RUNNING ON: {}\".format(d))\n",
    "    files = [x for x in image_search(glob.glob(os.path.join(d,'*')), IMAGE_REGEX)]\n",
    "    files = [x for x in files if not x.startswith('.')]\n",
    "    for f in tqdm_notebook(files):\n",
    "        _n = get_filename_data(f)\n",
    "        _class_dir = os.path.normpath(f).split(os.sep)[-2]\n",
    "        _name = make_filename(_n)\n",
    "        _newname = os.path.join(_DEST, _class_dir, _name)\n",
    "        to_save.append((f,_newname)) # (src, dest)\n",
    "        if _n['SET'] == 1: # train -> augment\n",
    "            augments = make_augments(f, 100)\n",
    "            _index = 1\n",
    "            for a in augments:\n",
    "                _new_n = _n.copy() # shallow\n",
    "                _n['AUGMENTID'] = _index\n",
    "                _index += 1\n",
    "                _new_filename = make_filename(_n)\n",
    "                _new_dir = os.path.join(_DEST, _class_dir)\n",
    "                if not os.path.isdir(_new_dir):\n",
    "                    os.makedirs(_new_dir)\n",
    "                a.save(os.path.join(_new_dir, _new_filename))\n",
    "print('Saving files...')\n",
    "for f in to_save:\n",
    "    shutil.copyfile(f[0], f[1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# 9. Check number of images\n",
    "#####\n",
    "_out_string = 'DIRECTORY: {DIR}\\n\\tTRAIN: {train}\\n\\tVALIDATE: {val}\\n\\tTEST: {test}\\n\\tTOTAL: {total}'\n",
    "_SRC = os.path.join(TOP_LEVEL, '6_EXPERIMENT_FINAL_ORIGINAL_SIZE')\n",
    "dirs = [x[0] for x in os.walk(_SRC)][1:] # first is src, remove\n",
    "for d in dirs:\n",
    "    files = [x for x in image_search(glob.glob(os.path.join(d,'*')), IMAGE_REGEX)]\n",
    "    num_train = num_val = num_test = 0\n",
    "    for f in files:\n",
    "        _n = get_filename_data(f)\n",
    "        if _n['SET'] == 1:\n",
    "            num_train += 1\n",
    "        if _n['SET'] == 2:\n",
    "            num_val += 1\n",
    "        if _n['SET'] == 3:\n",
    "            num_test += 1\n",
    "    print(_out_string.format(\n",
    "        DIR = os.path.basename(d),\n",
    "        train = num_train,\n",
    "        val = num_val,\n",
    "        test = num_test,\n",
    "        total = num_train + num_val + num_test\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# 10. Make sure all images are valid\n",
    "#####\n",
    "_SRC = os.path.join(TOP_LEVEL, '6_EXPERIMENT_FINAL_ORIGINAL_SIZE')\n",
    "dirs = [x[0] for x in os.walk(_SRC)][1:] # first is src, remove\n",
    "all_files = []\n",
    "for d in dirs:\n",
    "    files = [x for x in image_search(glob.glob(os.path.join(d,'*')), IMAGE_REGEX)]\n",
    "    all_files.extend(files)\n",
    "s = set()\n",
    "for f in tqdm_notebook(all_files):\n",
    "    _b = os.path.basename(f)\n",
    "    _class_dir = os.path.normpath(f).split(os.sep)[-2]\n",
    "    try:\n",
    "        _load(f)\n",
    "    except Exception as e:\n",
    "        _n = get_filename_data(f)\n",
    "        s.add((_n['CLASS'], _n['VIEW'],_n['INDEX']))\n",
    "# some images didn't save correctly / got corrupted, time to prune the weeds\n",
    "for a in s:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# 11. Resize all images\n",
    "#####\n",
    "\n",
    "_SRC = os.path.join(TOP_LEVEL, '6_EXPERIMENT_FINAL_ORIGINAL_SIZE')\n",
    "_DEST = os.path.join(TOP_LEVEL, '7_EXPERIMENT_FINAL_{}')\n",
    "dirs = [x[0] for x in os.walk(_SRC)][1:] # first is src, remove\n",
    "\n",
    "to_run = []\n",
    "\n",
    "all_files = []\n",
    "for d in dirs:\n",
    "    if len(to_run) != 0 and sum(1 for x in to_run if d.endswith(x)) == 0:\n",
    "        continue\n",
    "    files = [x for x in image_search(glob.glob(os.path.join(d,'*')), IMAGE_REGEX)]\n",
    "    all_files.extend(files)\n",
    "\n",
    "for f in tqdm_notebook(all_files):\n",
    "    _b = os.path.basename(f)\n",
    "    _class_dir = os.path.normpath(f).split(os.sep)[-2]\n",
    "    for i in [224, 299]:\n",
    "        _newdir = os.path.join(_DEST.format(i), _class_dir)\n",
    "        if not os.path.isdir(_newdir):\n",
    "            os.makedirs(_newdir)\n",
    "        _data = get_filename_data(_b)\n",
    "        _data['RESIZE'] = i\n",
    "        _newname = make_filename(_data)\n",
    "        _newname = os.path.join(_newdir, _newname)\n",
    "        _resized = _resize(f, DIMENSION=i)\n",
    "        _resized.save(_newname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# 12. Make spreadsheet of numbers gathered in final_dict\n",
    "#####\n",
    "\n",
    "_src = os.path.join(TOP_LEVEL, \"7_EXPERIMENT_FINAL_224\")\n",
    "column_names = ['Implant', 'Num_AP', 'Num_LATERAL', 'Total']\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "images = os.walk(_src)\n",
    "for i in images:\n",
    "    print(i)\n",
    "    break\n",
    "# for k in final_dict.keys():\n",
    "#     num_ap = 0\n",
    "#     num_lateral = 0\n",
    "#     for image in final_dict[k]:\n",
    "#         if image['VIEW'] == 'AP':\n",
    "#             num_ap += 1\n",
    "#         elif image['VIEW'] == 'LATERAL':\n",
    "#             num_lateral += 1\n",
    "#         else:\n",
    "#             assert 1==0\n",
    "#     toAdd = {'Implant' : k,\n",
    "#             'Num_AP' : num_ap,\n",
    "#             'Num_LATERAL' : num_lateral,\n",
    "#             'Total': num_ap + num_lateral}\n",
    "#     df = df.append(toAdd,ignore_index = True)\n",
    "\n",
    "# df.to_csv('ImplantNumbers.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# 13. Make Keras style train, validate, test directories\n",
    "#####\n",
    "_SRC = os.path.join(TOP_LEVEL, \"7_EXPERIMENT_FINAL_299\")\n",
    "_DEST = os.path.join(TOP_LEVEL, \"8_VGG_224\")\n",
    "\n",
    "dirs = [x[0] for x in os.walk(_SRC)][1:]\n",
    "all_files = []\n",
    "\n",
    "# make directory tree as follows:\n",
    "# data\n",
    "#     train\n",
    "#         class_1\n",
    "#            images\n",
    "#     validation\n",
    "#         class_1\n",
    "#            images\n",
    "\n",
    "for d in dirs:\n",
    "    files = [x for x in image_search(glob.glob(os.path.join(d,'*')), IMAGE_REGEX)]\n",
    "    all_files.extend(files)\n",
    "    \n",
    "for image in tqdm_notebook(all_files):\n",
    "    _class = os.path.dirname(image).split(os.sep)[-1]\n",
    "    _data = get_filename_data(image)\n",
    "    if _data['SET'] == 1:\n",
    "        _type = \"train\"\n",
    "    elif _data[\"SET\"] == 2:\n",
    "        _type = \"validation\"\n",
    "    elif _data[\"SET\"] == 3:\n",
    "        _type = \"test\"\n",
    "    else:\n",
    "        raise Exception(\"SET not valid\")\n",
    "    if _data['AUGMENTID'] != '0':\n",
    "        continue\n",
    "    _newdir = \"{}/{}/{}\".format(_DEST, _type, _class)\n",
    "    if not os.path.exists(_newdir):\n",
    "        os.makedirs(_newdir)\n",
    "    shutil.copyfile(image, os.path.join(_newdir, os.path.basename(image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "img = Image.open('/Volumes/MEDIA/ArthoplastyID/HIPS/5_EXPERIMENT_NAMES/BIOMET+ARCOS/BIOMET+ARCOS_AP_11_0_1_0.png')\n",
    "\n",
    "from keras.preprocessing.image import *\n",
    "#         rotation_range=40,\n",
    "#         width_shift_range=0.2,\n",
    "#         height_shift_range=0.2,\n",
    "#         brightness_range=(0.5, 1.2),\n",
    "#         shear_range=0.2,\n",
    "#         zoom_range=0.2,\n",
    "#         horizontal_flip=True,\n",
    "#         fill_mode='nearest')\n",
    "img = img_to_array(img)\n",
    "img = img.reshape((1,) + img.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "imgen = ImageDataGenerator(fill_mode='nearest').flow(img)\n",
    "fig, ax = plt.subplots(1, 10, figsize=(20, 10))\n",
    "ax = ax.ravel()\n",
    "ax[0].imshow(img[0].astype(int))\n",
    "for i in range(1,10):\n",
    "    ax[i].imshow(next(imgen)[0].astype(int))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "# Old, one-off functions\n",
    "##########\n",
    "\n",
    "def rename_bhr():\n",
    "    r = re.compile(r'[^\\.].*?\\.png$', flags = re.IGNORECASE)\n",
    "    for root, dirs, files in os.walk(dir_path):\n",
    "        l = [os.path.join(root,x) for x in files if r.match(x)]\n",
    "    for f in l:\n",
    "        if \"BHR\" in f:\n",
    "            d = os.path.dirname(f)\n",
    "            n = os.path.basename(f)\n",
    "            n = n.replace('-',' ')\n",
    "            n = n.replace('BHR', 'Birmingham')\n",
    "            new_name = os.path.join(d,n)\n",
    "            print('{}: {} -> {}'.format(os.path.dirname(f), \n",
    "                            os.path.basename(f),\n",
    "                            os.path.basename(new_name)))\n",
    "            os.rename(f, new_name)\n",
    "            \n",
    "def contour_test():\n",
    "    image = cv2.imread(image_path)\n",
    "    blurred = cv2.GaussianBlur(image, (11,11),0)\n",
    "    thresh = cv2.threshold(blurred, 160, 255, cv2.THRESH_BINARY)[1]\n",
    "    _show(blurred)\n",
    "    _show(thresh)\n",
    "\n",
    "    # convert to RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "    _show(binary)\n",
    "    contours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # draw all contours\n",
    "    image = cv2.drawContours(image, contours, -1, (0, 255, 0), 2)\n",
    "    _show(_load(image_path))\n",
    "    _show(_crop(_load(image_path), _smart_crop_coordinates(_load(image_path))))\n",
    "    \n",
    "\n",
    "def failed_buffer():\n",
    "    image = _load(image_path)\n",
    "    _BLACK = [0,0,0]\n",
    "\n",
    "    image = cv2.copyMakeBorder(cv2.imread(image_path), 0, 0, 0, 171, \n",
    "                               cv2.BORDER_CONSTANT, value = _BLACK)\n",
    "    image = Image.fromarray(image)\n",
    "\n",
    "    _show(image)\n",
    "    coords = auto_crop_coordinates(image)\n",
    "    print(coords)\n",
    "\n",
    "    im = auto_crop_main(image, debug = True)\n",
    "\n",
    "    _show(_crop(image,coords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = re.compile(r'[^\\.].*?\\.png$', flags = re.IGNORECASE)\n",
    "for root, dirs, files in os.walk(LATERAL):\n",
    "    l = [os.path.join(root,x) for x in files if r.match(x)]\n",
    "for f in l:\n",
    "    if \"M:L\".upper() in f.upper():\n",
    "        d = os.path.dirname(f)\n",
    "        n = os.path.basename(f)\n",
    "        n = n.replace('-',' ')\n",
    "        n = re.sub('M:L', 'ML',f, flags = re.IGNORECASE)\n",
    "        new_name = os.path.join(d,n)\n",
    "        print('{}: {} -> {}'.format(os.path.dirname(f), \n",
    "                            os.path.basename(f),\n",
    "                            os.path.basename(new_name)))\n",
    "#         print(new_name)\n",
    "        os.rename(f, new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
