{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "# Hip Implant Detector Master Code Repository\n",
    "# \n",
    "# (C) Jaret Karnuta 2020\n",
    "#\n",
    "###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from abc import ABC, abstractmethod\n",
    "import h5py\n",
    "import numpy as np\n",
    "from keras.models import load_model, Model\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "%matplotlib inline\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####\n",
    "# Image preprocessing\n",
    "# Statics to avoid memory overhead \n",
    "\n",
    "class ImageProcessor:\n",
    "    @staticmethod\n",
    "    def load_image(image_path, target_size = None):\n",
    "        return image.load_img(image_path, target_size = target_size)\n",
    "    @staticmethod\n",
    "    def _process_image(img, \n",
    "                    processing_function):\n",
    "        # makes image 3D array [x,y,channels]\n",
    "        x = image.img_to_array(img)\n",
    "        # turns image into batch-compatible image\n",
    "        # 4D array, [1, x, y, channels]\n",
    "        x = np.expand_dims(x, axis = 0)\n",
    "        x = processing_function(x)\n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def _load_process(image_path, target_size, processing_function):\n",
    "        img = ImageProcessor.load_image(image_path, target_size)\n",
    "        return ImageProcessor._process_image(img, processing_function)\n",
    "    @staticmethod\n",
    "    def inceptionV3(image_path):\n",
    "        from keras.applications.inception_v3 import preprocess_input\n",
    "        return ImageProcessor._load_process(image_path, \n",
    "                                          (299,299), \n",
    "                                          preprocess_input)\n",
    "    @staticmethod\n",
    "    def resnet50(image_path):\n",
    "        from keras.applications.resnet50 import preprocess_input\n",
    "        return ImageProcessor._load_process(image_path, \n",
    "                                          (224, 224), \n",
    "                                          preprocess_input)\n",
    "    @staticmethod\n",
    "    def vgg16(image_path):\n",
    "        from keras.applications.vgg16 import preprocess_input\n",
    "        return ImageProcessor._load_process(image_path,\n",
    "                                           (224,224),\n",
    "                                           preprocess_input)\n",
    "    \n",
    "    @staticmethod\n",
    "    def show_image(image):\n",
    "        plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abstract predictor\n",
    "class AbstractPredictor:\n",
    "    def predict(self, image):\n",
    "        # Predicts the class of the given image_path\n",
    "        # returns predictions in 1D list form\n",
    "        # e.g. [class_0_score, class_1_score, class_n_score]\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class defining Inception predictor\n",
    "class Predictor(AbstractPredictor):\n",
    "    \n",
    "    model = None\n",
    "    loaded = False\n",
    "    labels = None\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def load_model(self, model_definition):\n",
    "        self.model = load_model(model_definition)\n",
    "        self.loaded = True\n",
    "    \n",
    "    def load_architecture(self, architecture):\n",
    "        if isinstance(architecture, Model):\n",
    "            self.model = architecture\n",
    "            self.loaded = True\n",
    "        else:\n",
    "            raise ValueError(\"architecture must be keras.models.Model\")\n",
    "    \n",
    "    def load_weights(self, weights):\n",
    "        self.model.load_weights(weights)\n",
    "    \n",
    "    def load_labels(self, labels_file):\n",
    "        self.labels = np.load(labels_file, allow_pickle=True).item()\n",
    "    \n",
    "    def is_loaded(self):\n",
    "        return self.loaded\n",
    "    \n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    def _dict_predictions(self, preds, class_labels):\n",
    "        # given a list of predictions (class_0_score, class_1_score, etc)\n",
    "        # and class_labels {CLASS_0_LABEL:index_0, CLAS_1_LABEL:index_1,...}\n",
    "        # return a dictionray mapping scores to class labels\n",
    "        # {CLASS_LABEL_0:class_0_score, CLASS_LABEL_1:class_1_score, ...}\n",
    "        preds = np.squeeze(preds)\n",
    "        results = dict(zip(class_labels.keys(), preds))\n",
    "        return results\n",
    "            \n",
    "    def _top_k(self, zipped_preds, k = 5):\n",
    "        # given dictionaty of zipped predictions, return top k entries\n",
    "        # sorted decending by score\n",
    "        d = [(x,y) for x,y in zipped_preds.items()]\n",
    "        d = sorted(d, key = lambda x: x[1], reverse = True)\n",
    "        if k >= len(d):\n",
    "            return d\n",
    "        return d[:k]\n",
    "    \n",
    "    def predict(self, processed_image):\n",
    "        if not self.is_loaded():\n",
    "            raise Exception(\"Predictor has no valid model loaded\")\n",
    "        # make predictions\n",
    "        # processed image must be a pre-processed image per the specific model definition\n",
    "        # must be a 4D array (1, x, y, channels)\n",
    "        # see ImageProcessor for inceptionV3, resnet50, and vgg16 implementations\n",
    "        preds = self.model.predict(processed_image)\n",
    "        return preds\n",
    "\n",
    "    \n",
    "    def preds_df(self, preds, k = np.Inf):\n",
    "        dict_preds = self._dict_predictions(preds, self.labels)\n",
    "        top = self._top_k(dict_preds, k = k)\n",
    "        predictions = pd.DataFrame(top,columns=['category','probability'])\n",
    "        return predictions\n",
    "    \n",
    "    ##########\n",
    "    # BEGIN STATIC FUNCTIONS\n",
    "    ##########\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_predicted_index(preds):\n",
    "        return np.argmax(np.squeeze(preds))\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_predicted_class(preds_df):\n",
    "        return preds_df.loc[0,'category']\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_predictions(preds_df):\n",
    "        import seaborn as sns\n",
    "        f = sns.barplot(x='probability',y='category',data=preds_df,color=\"red\")\n",
    "        sns.set_style(style='white')\n",
    "        f.grid(False)\n",
    "        f.spines[\"top\"].set_visible(False)\n",
    "        f.spines[\"right\"].set_visible(False)\n",
    "        f.spines[\"bottom\"].set_visible(False)\n",
    "        f.spines[\"left\"].set_visible(False)\n",
    "        f.set_title('Top {} Prediction{}:'.format(\n",
    "            preds_df.shape[0],\n",
    "            \"\" if preds_df.shape[0] == 1 else \"s\"\n",
    "        ))\n",
    "        return f\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class defining Ludwig predictor (resnet50)\n",
    "\n",
    "class LudwithPredictor(AbstractPredictor):\n",
    "    \"\"\"\n",
    "    Due to constraints of Ludwig, you MUST have a separate prediction file that handles the ludwig-side logic\n",
    "    The file will then be called using a pipe and a ludwig-specific virtual environment\n",
    "    Ludwig has *very obnoxious* limitations regarding tensorflow versions (does not work with TF v2)\n",
    "    \n",
    "    Implemented in a separate file due to the above restraints\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def predict(self, *args, **kwargs):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class defining extracting attention graphs from model\n",
    "\n",
    "class ActivationMap:\n",
    "    \"\"\"\n",
    "    This is one way to visualize the gradient flow through a CNN\n",
    "    \n",
    "    This code takes an arbitrary model and created a heatmap of \n",
    "    class activations\n",
    "    \n",
    "    The heatmap is a 2D matrix of scores associated with \n",
    "    the given class at the last convolutional layer\n",
    "    \"\"\"\n",
    "    # CNN model used to generate the activation mapping\n",
    "    # Must be pre-instantiated\n",
    "    model = None\n",
    "    \n",
    "    # Last convolutional layer containing activation gradients\n",
    "    # Examples include:\n",
    "    # ----------------\n",
    "    # ResNet50: res5c_branch2c\n",
    "    # Inception V3: conv2d_94\n",
    "    # VGG16: block5_conv3\n",
    "    last_conv_layer_name = None\n",
    "    \n",
    "    def __init__(self, model, last_conv_layer):\n",
    "        self.model = model\n",
    "        if last_conv_layer == 'inceptionv3':\n",
    "            self.last_conv_layer_name = 'conv2d_94'\n",
    "        elif last_conv_layer == 'resnet50':\n",
    "            self.last_conv_layer_name = 'res5c_branch2makec'\n",
    "        elif  last_conv_layer == 'vgg16':\n",
    "            self.last_conv_layer_name = 'block5_conv3'\n",
    "        else:\n",
    "            self.last_conv_layer_name = last_conv_layer\n",
    "        \n",
    "        # validate last_conv_layer\n",
    "        try:\n",
    "            self.model.get_layer(self.last_conv_layer_name)\n",
    "        except ValueError as ve:\n",
    "            raise ve\n",
    "    \n",
    "    def _pooled_gradients(self,argmax, last_conv_layer):\n",
    "        # given argmax and a CNN, return the channel_pooled gradients for argmax\n",
    "        output = self.model.output[:,argmax]\n",
    "        gradients = K.gradients(output, last_conv_layer.output)[0]\n",
    "        pooled_gradients = K.mean(gradients, axis = (0,1,2))\n",
    "        #pooled gradients has a size of (192,) for inceptionV3\n",
    "        return pooled_gradients\n",
    "    \n",
    "    def _calculate_gradient_importances(self, \n",
    "                                        pooled_grads, \n",
    "                                        last_conv_layer,\n",
    "                                        image_tensor_scaled):\n",
    "        # access values within last convolutional layer and pooled gradients\n",
    "        iterate = K.function([self.model.input], [pooled_grads,last_conv_layer.output[0]])\n",
    "        # iterate across provided image tensor\n",
    "        pooled_grads_value, conv_layer_output_value = iterate([image_tensor_scaled])\n",
    "        for i in range(pooled_grads.shape[0]):\n",
    "            # multiply each channel in feature map by importance proxied by gradient value\n",
    "            # i.e. high gradients = high importance\n",
    "            conv_layer_output_value[:,:,i] *= pooled_grads_value[i]\n",
    "        return conv_layer_output_value\n",
    "    \n",
    "    def make_heatmap(self, conv_layer_output_value):\n",
    "        h = np.mean(conv_layer_output_value, axis = -1)\n",
    "        h = np.maximum(h, 0) # remove negatives\n",
    "        h /= np.max(h) # scale to [0,1]\n",
    "        return h\n",
    "        \n",
    "    \n",
    "    def activate(self, image_tensor_scaled, class_index):\n",
    "        # Params:\n",
    "        #     scaled image tensor (see ImageProcessor for calculating image tensors)\n",
    "        #     class_index of predictions\n",
    "        # Return:\n",
    "        #     Heatmap of activations at last convolutional layer\n",
    "        last_conv_layer = self.model.get_layer(self.last_conv_layer_name)\n",
    "        pooled_gradients = self._pooled_gradients(class_index, last_conv_layer)\n",
    "        grad_importances = self._calculate_gradient_importances(pooled_gradients,\n",
    "                                                               last_conv_layer,\n",
    "                                                               image_tensor_scaled)\n",
    "        heatmap = self.make_heatmap(grad_importances)\n",
    "        return heatmap\n",
    "    \n",
    "    @staticmethod\n",
    "    def superimpose(image_path, heatmap):\n",
    "        import cv2\n",
    "        # Given image_path to ORIGINAL image (not tensor)\n",
    "        # and heatmap calculated from ActivationMap.activate\n",
    "        # return original image superimposed with heatmap\n",
    "        img = cv2.imread(image_path)\n",
    "        # resize heatmap to fit image\n",
    "        # i.e. inception heatmap is 8x8 for 299x299 image input\n",
    "        h = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "        # convert [0,1] colors to [0,256)\n",
    "        h = np.uint8(255 * h)\n",
    "        # Apply colormap, JET provides nice contrast\n",
    "        h = cv2.applyColorMap(h, cv2.COLORMAP_JET)\n",
    "        # heatmap intensity factor, 0.5 still allows for visualizaton of original image\n",
    "        hif = .5\n",
    "        # apply heatmap over original image\n",
    "        superimposed_img = h * hif + img\n",
    "        return superimposed_img\n",
    "\n",
    "    @staticmethod\n",
    "    def save(image, output):\n",
    "        import cv2\n",
    "        cv2.imwrite(output, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileOps:\n",
    "    \"\"\"\n",
    "    Class containing static file operation helper functions\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    IMAGE_REGEX = re.compile(\".*?\\.(png|jpe?g)$\", flags = re.IGNORECASE)\n",
    "    EXTENSION = \".png\"\n",
    "    RENAME_TEMPLATE = '{CLASS}_{VIEW}_{INDEX}_{RESIZE}_{SET}_{AUGMENTID}.{EXTENSION}'\n",
    "    \n",
    "    @staticmethod\n",
    "    def traverse_directory_tree(path):\n",
    "        # returns all files within a file tree\n",
    "        all_images = []\n",
    "        for root,dirs,files in os.walk(path):\n",
    "            for file in files:\n",
    "                all_images.append(os.path.join(root,file))\n",
    "        return all_images\n",
    "    \n",
    "    @staticmethod        \n",
    "    def _search_list(files, regex):\n",
    "        # search for a given file in a given list of files\n",
    "        ret = []\n",
    "        for f in files:\n",
    "            if regex is not None:\n",
    "                if regex.search(f):\n",
    "                    ret.append(f)\n",
    "        return ret\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_filename_data(path):\n",
    "    # Expected format:\n",
    "    # '{DIRECTORY}/{CLASS}_{VIEW}_{INDEX}_{RESIZE}_{SET}_{AUGMENTID}.png'\n",
    "        base = os.path.basename(path)\n",
    "        _split = '.'.join(base.split('.')[:-1]).split('_')\n",
    "        _directory = os.path.dirname(path).split(os.sep)[-1]\n",
    "        _class = _split[0]\n",
    "        _view = _split[1]\n",
    "        _index = _split[2]\n",
    "        _resize = _split[3]\n",
    "        _set = _split[4]\n",
    "        _augment = _split[5]\n",
    "        return {\n",
    "            'DIRECTORY':_directory,\n",
    "            'CLASS':_class,\n",
    "            'VIEW':_view,\n",
    "            'INDEX':int(_index),\n",
    "            'RESIZE':int(_resize),\n",
    "            'SET':int(_set),\n",
    "            'AUGMENTID':_augment\n",
    "               }\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_filename(dictionary):\n",
    "        return FileOps.RENAME_TEMPLATE.format(\n",
    "                            CLASS = dictionary['CLASS'],\n",
    "                            VIEW = dictionary['VIEW'],\n",
    "                            INDEX = dictionary['INDEX'],\n",
    "                            RESIZE = dictionary['RESIZE'],\n",
    "                            SET = dictionary['SET'],\n",
    "                            AUGMENTID = dictionary['AUGMENTID'],\n",
    "                            EXTENSION = FileOps.EXTENSION\n",
    "                            )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading KERAS/inception_raw_trained/inception_299_trained_raw.h5...\n",
      "Loaded model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bcc3fec631a4445854d97feba2d102d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=206.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/premramkumar/Desktop/jmk/venv/JUPYTER/lib/python3.6/site-packages/ipykernel_launcher.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/premramkumar/Desktop/jmk/venv/JUPYTER/lib/python3.6/site-packages/ipykernel_launcher.py:67: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def inception_wrapper():\n",
    "    \n",
    "    # instantiate models\n",
    "    model_saved = \"KERAS/inception_raw_trained/inception_299_trained_raw.h5\"\n",
    "    labels = \"KERAS/inception_raw_trained/CLASS_LABELS.npy\"\n",
    "    \n",
    "    print(\"Loading {}...\".format(model_saved))\n",
    "    model = Predictor()\n",
    "    model.load_model(model_saved)\n",
    "    print(\"Loaded model\")\n",
    "    model.load_labels(labels)\n",
    "    \n",
    "    \n",
    "    pics = '/home/premramkumar/Desktop/jmk/ArthroplastyID/HIPS/8_VGG_224/test'\n",
    "    save_activation_dir = 'ACTIVATION_MAPS'\n",
    "    if not os.path.isdir(save_activation_dir):\n",
    "        os.makedirs(save_activation_dir)\n",
    "        \n",
    "    all_images = FileOps.traverse_directory_tree(pics)\n",
    "    \n",
    "    column_names = [\"implant_class\", \"implant_id\", \"implant_path\", \n",
    "                    \"top_1_class\", \"top_1_score\", \n",
    "                    \"top_2_class\", \"top_2_score\", \n",
    "                    \"top_3_class\", \"top_3_score\",\n",
    "                    \"correct\", \"k_3_correct\",\n",
    "                    \"activation_map_path\",\n",
    "                   ]\n",
    "    df = pd.DataFrame(columns = column_names)\n",
    "    for i in tqdm_notebook(all_images):\n",
    "        _data = FileOps.get_filename_data(i)\n",
    "        to_add = {\n",
    "            'implant_class': _data['DIRECTORY'],\n",
    "            'implant_id': _data[\"INDEX\"],\n",
    "            'implant_path': i,\n",
    "            'top_1_class': None,\n",
    "            'top_1_score': None,\n",
    "            'top_2_class': None,\n",
    "            'top_2_score': None,\n",
    "            'top_3_class': None,\n",
    "            'top_3_score': None,\n",
    "            'correct': None,\n",
    "            'k_3_correct': None,\n",
    "            'activation_map_path': None\n",
    "        }\n",
    "        \n",
    "        # load image\n",
    "        img = ImageProcessor.inceptionV3(i)\n",
    "        \n",
    "        # get predictions\n",
    "        preds = model.predict(img)\n",
    "        \n",
    "        # populate top_n_name and top_n_score\n",
    "        preds_df = model.preds_df(preds, k = 3)\n",
    "        to_add['top_1_class'] = preds_df.loc[0,'category']\n",
    "        to_add['top_1_score'] = preds_df.loc[0,'probability']\n",
    "        to_add['top_2_class'] = preds_df.loc[1,'category']\n",
    "        to_add['top_2_score'] = preds_df.loc[1,'probability']\n",
    "        to_add['top_3_class'] = preds_df.loc[2,'category']\n",
    "        to_add['top_3_score'] = preds_df.loc[2,'probability']\n",
    "        \n",
    "        # calculate correct variable\n",
    "        to_add['correct'] = 1 if to_add['implant_class'] == to_add['top_1_class'] else 0\n",
    "        top_3 = preds_df['category'].tolist()\n",
    "        to_add['k_3_correct'] = 1 if to_add['implant_class'] in top_3 else 0\n",
    "        \n",
    "        # calculate attention map and save to directory\n",
    "        \n",
    "        output_base = os.path.basename(i).split('.')[0] + '.saliency.png'\n",
    "        output_relative = os.path.join(save_activation_dir, output_base)\n",
    "        output_absolute = os.path.abspath(output_relative)\n",
    "        \n",
    "        argmax = Predictor.get_predicted_index(preds)\n",
    "        am = ActivationMap(model.get_model(), 'inceptionv3')\n",
    "        heatmap = am.activate(img, argmax)\n",
    "        superimg = ActivationMap.superimpose(i, heatmap)\n",
    "        ActivationMap.save(superimg, output_relative)\n",
    "        \n",
    "        to_add['activation_map_path'] = output_absolute\n",
    "#         print(to_add)\n",
    "        df = df.append(to_add, ignore_index = True)\n",
    "    df.to_csv('inception_raw_final.csv', index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
